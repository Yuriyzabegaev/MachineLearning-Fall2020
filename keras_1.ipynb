{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28) (50000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def load_dataset(flatten=False):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    # normalize x\n",
    "    X_train = X_train.astype(float) / 255.\n",
    "    X_test = X_test.astype(float) / 255.\n",
    "    \n",
    "    # Оставим 10000 примеров на валидацию\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "    if flatten:\n",
    "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
    "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
    "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "## Размеры\n",
    "print(X_train.shape, y_train.shape)\n",
    "## Нарисуем пример\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dimension:\n",
      "(50000, 784)\n",
      "Test dimension:\n",
      "(10000, 784)\n",
      "Train labels dimension:\n",
      "(50000, 10)\n",
      "Test labels dimension:\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "## Сделаем объекты плоскими N*28*28 to  N*784\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "\n",
    "## Лейблы нужно сделать One-Hot\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "print('Train labels dimension:');print(y_train.shape)\n",
    "print('Test labels dimension:');print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(14, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='SGD', \n",
    "              metrics=['mean_squared_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0866 - mean_squared_error: 0.0866 - accuracy: 0.2040 - val_loss: 0.0823 - val_mean_squared_error: 0.0823 - val_accuracy: 0.2995\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0775 - mean_squared_error: 0.0775 - accuracy: 0.3234 - val_loss: 0.0714 - val_mean_squared_error: 0.0714 - val_accuracy: 0.3688\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0665 - mean_squared_error: 0.0665 - accuracy: 0.4556 - val_loss: 0.0602 - val_mean_squared_error: 0.0602 - val_accuracy: 0.5261\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0545 - mean_squared_error: 0.0545 - accuracy: 0.6094 - val_loss: 0.0462 - val_mean_squared_error: 0.0462 - val_accuracy: 0.6945\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0418 - mean_squared_error: 0.0418 - accuracy: 0.7287 - val_loss: 0.0350 - val_mean_squared_error: 0.0350 - val_accuracy: 0.7871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e58017e80>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=10, \n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - accuracy: 0.7871\n",
      "Test loss: 0.03503701835870743, test mse: 0.03503701835870743, test accuracy: 0.7871000170707703\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание\n",
    "1. Выбрать верный loss\n",
    "2. Добавить accuracy как оценку качества\n",
    "3. Исследовать изменение качества при\n",
    "        3.1. Изменении числа слоев\n",
    "        3.2. Изменении числа нейронов\n",
    "        3.3. Изменение функции активации\n",
    "3. Исследовать параметры SGD, сделать выводы\n",
    "\n",
    "```\n",
    "tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\", **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бинарная кроссэнтропия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 1s 3ms/step - loss: 0.1294 - mean_squared_error: 0.0355 - accuracy: 0.7761\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1224 - mean_squared_error: 0.0335 - accuracy: 0.7880\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1163 - mean_squared_error: 0.0317 - accuracy: 0.7992\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1111 - mean_squared_error: 0.0301 - accuracy: 0.8082\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 1s 2ms/step - loss: 0.1066 - mean_squared_error: 0.0288 - accuracy: 0.8160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e572803a0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0989 - mean_squared_error: 0.0264 - accuracy: 0.8343\n",
      "Test loss: 0.09885917603969574, test mse: 0.026367774233222008, test accuracy: 0.8342999815940857\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Плюс слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.3087 - mean_squared_error: 0.0867 - accuracy: 0.2556\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2668 - mean_squared_error: 0.0762 - accuracy: 0.6131\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2219 - mean_squared_error: 0.0631 - accuracy: 0.7173\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.1803 - mean_squared_error: 0.0501 - accuracy: 0.7758\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1483 - mean_squared_error: 0.0402 - accuracy: 0.8133\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1307 - mean_squared_error: 0.0348 - accuracy: 0.8371\n",
      "Test loss: 0.13069622218608856, test mse: 0.034793954342603683, test accuracy: 0.8371000289916992\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Изменим число нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.3086 - mean_squared_error: 0.0866 - accuracy: 0.2691\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2719 - mean_squared_error: 0.0776 - accuracy: 0.4691\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.2362 - mean_squared_error: 0.0673 - accuracy: 0.5764\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2033 - mean_squared_error: 0.0574 - accuracy: 0.6689\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1736 - mean_squared_error: 0.0482 - accuracy: 0.7443\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1555 - mean_squared_error: 0.0425 - accuracy: 0.7892\n",
      "Test loss: 0.15548422932624817, test mse: 0.04246830567717552, test accuracy: 0.7892000079154968\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Везде софтмакс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.3251 - mean_squared_error: 0.0900 - accuracy: 0.0963\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3251 - mean_squared_error: 0.0900 - accuracy: 0.1136\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.3251 - mean_squared_error: 0.0900 - accuracy: 0.1136\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 6s 14ms/step - loss: 0.3250 - mean_squared_error: 0.0900 - accuracy: 0.1136\n",
      "Epoch 5/5\n",
      "241/391 [=================>............] - ETA: 2s - loss: 0.3250 - mean_squared_error: 0.0900 - accuracy: 0.1128"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-ce8355a5400e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 metrics = ['mean_squared_error', 'accuracy'])\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='softmax', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='softmax'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Везде релу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 2.4467 - mean_squared_error: 3.3504 - accuracy: 0.1102\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 1.7485 - mean_squared_error: 6.4224 - accuracy: 0.3291\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 2.9833 - mean_squared_error: 61.5401 - accuracy: 0.0993\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 3.4770 - mean_squared_error: 64.0745 - accuracy: 0.0989\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 4.6558 - mean_squared_error: 67.7411 - accuracy: 0.0996\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 4.9072 - mean_squared_error: 72.6363 - accuracy: 0.1007\n",
      "Test loss: 4.907151222229004, test mse: 72.63626098632812, test accuracy: 0.1006999984383583\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.3064 - mean_squared_error: 0.0862 - accuracy: 0.3312\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.2652 - mean_squared_error: 0.0760 - accuracy: 0.6450\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2205 - mean_squared_error: 0.0627 - accuracy: 0.7287\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.1788 - mean_squared_error: 0.0496 - accuracy: 0.7765\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.1471 - mean_squared_error: 0.0399 - accuracy: 0.8116\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.1302 - mean_squared_error: 0.0348 - accuracy: 0.8369\n",
      "Test loss: 0.13017894327640533, test mse: 0.03475549444556236, test accuracy: 0.836899995803833\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "sgd = SGD(\n",
    "    learning_rate=0.01, momentum=0.0, nesterov=False, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.3053 - mean_squared_error: 0.0858 - accuracy: 0.3274\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2626 - mean_squared_error: 0.0751 - accuracy: 0.5965\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.2172 - mean_squared_error: 0.0616 - accuracy: 0.7049\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.1761 - mean_squared_error: 0.0489 - accuracy: 0.7648\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.1456 - mean_squared_error: 0.0395 - accuracy: 0.8022\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1288 - mean_squared_error: 0.0344 - accuracy: 0.8284\n",
      "Test loss: 0.12879112362861633, test mse: 0.03444591537117958, test accuracy: 0.8284000158309937\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(\n",
    "    learning_rate=0.01, momentum=0.0, nesterov=True, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.3069 - mean_squared_error: 0.0863 - accuracy: 0.3372\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.2613 - mean_squared_error: 0.0749 - accuracy: 0.6809\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.2101 - mean_squared_error: 0.0594 - accuracy: 0.7588\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.1648 - mean_squared_error: 0.0451 - accuracy: 0.7968\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.1336 - mean_squared_error: 0.0357 - accuracy: 0.8241\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1171 - mean_squared_error: 0.0307 - accuracy: 0.8477\n",
      "Test loss: 0.11709082126617432, test mse: 0.03069118596613407, test accuracy: 0.8476999998092651\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(\n",
    "    learning_rate=0.01, momentum=0.1, nesterov=False, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.3043 - mean_squared_error: 0.0858 - accuracy: 0.3667\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 7s 19ms/step - loss: 0.2581 - mean_squared_error: 0.0740 - accuracy: 0.6722\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.2088 - mean_squared_error: 0.0590 - accuracy: 0.7529\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 6s 15ms/step - loss: 0.1662 - mean_squared_error: 0.0457 - accuracy: 0.7964\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.1357 - mean_squared_error: 0.0363 - accuracy: 0.8246\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1196 - mean_squared_error: 0.0315 - accuracy: 0.8459\n",
      "Test loss: 0.1196373999118805, test mse: 0.03149662911891937, test accuracy: 0.8458999991416931\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(\n",
    "    learning_rate=0.01, momentum=0.1, nesterov=True, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 0.2252 - mean_squared_error: 0.0633 - accuracy: 0.6485\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.1007 - mean_squared_error: 0.0265 - accuracy: 0.8528\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 11s 29ms/step - loss: 0.0725 - mean_squared_error: 0.0188 - accuracy: 0.8846\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 10s 27ms/step - loss: 0.0621 - mean_squared_error: 0.0161 - accuracy: 0.8975\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.0562 - mean_squared_error: 0.0146 - accuracy: 0.9061\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0508 - mean_squared_error: 0.0131 - accuracy: 0.9153\n",
      "Test loss: 0.0507955327630043, test mse: 0.013056233525276184, test accuracy: 0.9153000116348267\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(\n",
    "    learning_rate=0.05, momentum=0.1, nesterov=False, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.1564 - mean_squared_error: 0.0430 - accuracy: 0.7557\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0666 - mean_squared_error: 0.0173 - accuracy: 0.8910\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 6s 16ms/step - loss: 0.0547 - mean_squared_error: 0.0142 - accuracy: 0.9082\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.0488 - mean_squared_error: 0.0126 - accuracy: 0.9184\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 7s 18ms/step - loss: 0.0447 - mean_squared_error: 0.0115 - accuracy: 0.9254\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0420 - mean_squared_error: 0.0108 - accuracy: 0.9302\n",
      "Test loss: 0.04197448864579201, test mse: 0.01080775260925293, test accuracy: 0.9301999807357788\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(\n",
    "    learning_rate=0.1, momentum=0.1, nesterov=False, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.1068 - mean_squared_error: 0.0289 - accuracy: 0.8257\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.0494 - mean_squared_error: 0.0128 - accuracy: 0.9167\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.0405 - mean_squared_error: 0.0104 - accuracy: 0.9324\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.0345 - mean_squared_error: 0.0088 - accuracy: 0.9426:\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 10s 26ms/step - loss: 0.0301 - mean_squared_error: 0.0077 - accuracy: 0.9499\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0292 - mean_squared_error: 0.0075 - accuracy: 0.9516\n",
      "Test loss: 0.029152672737836838, test mse: 0.007503910921514034, test accuracy: 0.9516000151634216\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(\n",
    "    learning_rate=0.25, momentum=0.1, nesterov=False, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.0777 - mean_squared_error: 0.0208 - accuracy: 0.8715\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.0389 - mean_squared_error: 0.0101 - accuracy: 0.9348\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 10s 25ms/step - loss: 0.0292 - mean_squared_error: 0.0075 - accuracy: 0.9516\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.0233 - mean_squared_error: 0.0059 - accuracy: 0.9617\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 9s 24ms/step - loss: 0.0195 - mean_squared_error: 0.0049 - accuracy: 0.9682\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0218 - mean_squared_error: 0.0058 - accuracy: 0.9624\n",
      "Test loss: 0.021841492503881454, test mse: 0.005755283869802952, test accuracy: 0.9624000191688538\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(\n",
    "    learning_rate=0.5, momentum=0.1, nesterov=False, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.0631 - mean_squared_error: 0.0170 - accuracy: 0.8876\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 10s 24ms/step - loss: 0.0276 - mean_squared_error: 0.0071 - accuracy: 0.9537\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.0194 - mean_squared_error: 0.0050 - accuracy: 0.9672\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.0146 - mean_squared_error: 0.0037 - accuracy: 0.9759\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 7s 17ms/step - loss: 0.0114 - mean_squared_error: 0.0029 - accuracy: 0.9813\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0141 - mean_squared_error: 0.0038 - accuracy: 0.9746\n",
      "Test loss: 0.0141352079808712, test mse: 0.003811461618170142, test accuracy: 0.9746000170707703\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(\n",
    "    learning_rate=1, momentum=0.1, nesterov=False, name=\"SGD\"\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "                loss='binary_crossentropy',\n",
    "                metrics = ['mean_squared_error', 'accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128)\n",
    "\n",
    "test_loss, test_mse, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2 по керасу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "input1 = Input(shape=(28 * 28,))\n",
    "hidden1 = Dense(512, activation='relu')(input1)\n",
    "hidden2 = Dense(256, activation='relu')(hidden1)\n",
    "output = Dense(10, activation='softmax')(hidden2)\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', \n",
    "              metrics=['accuracy', 'mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3336 - accuracy: 0.0507 - mean_squared_error: 0.0916\n",
      "Test loss: 0.3336113691329956, test mse: 0.0915769413113594, test accuracy: 0.050700001418590546\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_mse = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   1/1563 [..............................] - ETA: 0s - loss: 0.0434 - accuracy: 0.9375 - mean_squared_error: 0.0106WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0070s vs `on_train_batch_end` time: 0.0205s). Check your callbacks.\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.0320 - accuracy: 0.9478 - mean_squared_error: 0.0081 - val_loss: 0.0315 - val_accuracy: 0.9471 - val_mean_squared_error: 0.0081\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.0313 - accuracy: 0.9490 - mean_squared_error: 0.0079 - val_loss: 0.0309 - val_accuracy: 0.9491 - val_mean_squared_error: 0.0079\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.01,\n",
    "                              patience=0,\n",
    "                              verbose=2, mode='auto')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), \n",
    "                    callbacks=[tensorboard_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a198c9add02835d9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a198c9add02835d9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   2/1563 [..............................] - ETA: 1:31 - loss: 0.3351 - accuracy: 0.0625 - mean_squared_error: 0.0918WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0168s vs `on_train_batch_end` time: 0.0995s). Check your callbacks.\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.3053 - accuracy: 0.3580 - mean_squared_error: 0.0859 - val_loss: 0.2789 - val_accuracy: 0.6258 - val_mean_squared_error: 0.0798\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 0.2519 - accuracy: 0.6897 - mean_squared_error: 0.0721 - val_loss: 0.2201 - val_accuracy: 0.7404 - val_mean_squared_error: 0.0625\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.1957 - accuracy: 0.7611 - mean_squared_error: 0.0547 - val_loss: 0.1672 - val_accuracy: 0.7964 - val_mean_squared_error: 0.0459\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1526 - accuracy: 0.8045 - mean_squared_error: 0.0414 - val_loss: 0.1321 - val_accuracy: 0.8309 - val_mean_squared_error: 0.0352\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.1250 - accuracy: 0.8316 - mean_squared_error: 0.0332 - val_loss: 0.1101 - val_accuracy: 0.8524 - val_mean_squared_error: 0.0287\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.1074 - accuracy: 0.8496 - mean_squared_error: 0.0281 - val_loss: 0.0959 - val_accuracy: 0.8689 - val_mean_squared_error: 0.0247\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.0956 - accuracy: 0.8607 - mean_squared_error: 0.0249 - val_loss: 0.0863 - val_accuracy: 0.8766 - val_mean_squared_error: 0.0221\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28 * 28,))\n",
    "hidden1 = Dense(512, activation='relu')(input1)\n",
    "hidden2 = Dense(256, activation='relu')(hidden1)\n",
    "output = Dense(10, activation='softmax')(hidden2)\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.compile(optimizer='Adagrad', loss='binary_crossentropy', \n",
    "              metrics=['accuracy', 'mean_squared_error'])\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.01,\n",
    "                              patience=0,\n",
    "                              verbose=2, mode='auto')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), \n",
    "                    callbacks=[tensorboard_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   2/1563 [..............................] - ETA: 1:22 - loss: 0.3273 - accuracy: 0.1875 - mean_squared_error: 0.0902WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0090s vs `on_train_batch_end` time: 0.0983s). Check your callbacks.\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 0.0358 - accuracy: 0.9367 - mean_squared_error: 0.0095 - val_loss: 0.0180 - val_accuracy: 0.9679 - val_mean_squared_error: 0.0048\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 0.0161 - accuracy: 0.9719 - mean_squared_error: 0.0042 - val_loss: 0.0221 - val_accuracy: 0.9610 - val_mean_squared_error: 0.0059\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(28 * 28,))\n",
    "hidden1 = Dense(512, activation='relu')(input1)\n",
    "hidden2 = Dense(256, activation='relu')(hidden1)\n",
    "output = Dense(10, activation='softmax')(hidden2)\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy', 'mean_squared_error'])\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.01,\n",
    "                              patience=0,\n",
    "                              verbose=2, mode='auto')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), \n",
    "                    callbacks=[tensorboard_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchNorm / Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "   2/1563 [..............................] - ETA: 2:42 - loss: 0.3558 - accuracy: 0.1406 - mean_squared_error: 0.0959WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0092s vs `on_train_batch_end` time: 0.1979s). Check your callbacks.\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.0514 - accuracy: 0.9069 - mean_squared_error: 0.0139 - val_loss: 0.0211 - val_accuracy: 0.9628 - val_mean_squared_error: 0.0056\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.0301 - accuracy: 0.9455 - mean_squared_error: 0.0081 - val_loss: 0.0155 - val_accuracy: 0.9726 - val_mean_squared_error: 0.0041\n",
      "Epoch 00002: early stopping\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, BatchNormalization, Activation\n",
    "\n",
    "input1 = Input(shape=(28 * 28,))\n",
    "hidden1 = Dense(512)(input1)\n",
    "hidden2 = BatchNormalization()(hidden1)\n",
    "hidden3 = Activation('relu')(hidden2)\n",
    "hidden4 = Dropout(0.5)(hidden3)\n",
    "\n",
    "hidden5 = Dense(256)(hidden4)\n",
    "hidden6 = BatchNormalization()(hidden5)\n",
    "hidden7 = Activation('relu')(hidden6)\n",
    "\n",
    "output = Dense(10, activation='softmax')(hidden7)\n",
    "\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', \n",
    "              metrics=['accuracy', 'mean_squared_error'])\n",
    "\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.01,\n",
    "                              patience=0,\n",
    "                              verbose=2, mode='auto')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), \n",
    "                    callbacks=[tensorboard_callback, early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0155 - accuracy: 0.9726 - mean_squared_error: 0.0041\n",
      "Test loss: 0.015509144403040409, test mse: 0.004146759398281574, test accuracy: 0.972599983215332\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_mse  = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}, test mse: {test_mse}, test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras-tuner-1.0.2.tar.gz (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from keras-tuner) (20.4)\n",
      "Requirement already satisfied: future in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from keras-tuner) (0.18.2)\n",
      "Requirement already satisfied: numpy in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from keras-tuner) (1.19.2)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting terminaltables\n",
      "  Downloading terminaltables-3.1.0.tar.gz (12 kB)\n",
      "Requirement already satisfied: colorama in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from keras-tuner) (0.4.4)\n",
      "Requirement already satisfied: tqdm in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from keras-tuner) (4.50.2)\n",
      "Requirement already satisfied: requests in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from keras-tuner) (2.24.0)\n",
      "Requirement already satisfied: scipy in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from keras-tuner) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from keras-tuner) (0.23.2)\n",
      "Requirement already satisfied: six in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from packaging->keras-tuner) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from packaging->keras-tuner) (2.4.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from requests->keras-tuner) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from requests->keras-tuner) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from requests->keras-tuner) (2.10)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from scikit-learn->keras-tuner) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/zabegaev99/anaconda3/lib/python3.8/site-packages (from scikit-learn->keras-tuner) (2.1.0)\n",
      "Building wheels for collected packages: keras-tuner, terminaltables\n",
      "  Building wheel for keras-tuner (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-py3-none-any.whl size=78936 sha256=a4125aa0fba24ff5ed79eabbe6dec826fd65ff0d888e2ff332d9fbec71b68af9\n",
      "  Stored in directory: /Users/zabegaev99/Library/Caches/pip/wheels/53/3d/c3/160c686bd74a18989843fcd015e8f6954ca8d834fd2ef4658a\n",
      "  Building wheel for terminaltables (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for terminaltables: filename=terminaltables-3.1.0-py3-none-any.whl size=15354 sha256=5387d88e4777ce641c010153d3e671e5f3418b804ecc2d43f8f6998f4f564d62\n",
      "  Stored in directory: /Users/zabegaev99/Library/Caches/pip/wheels/08/8f/5f/253d0105a55bd84ee61ef0d37dbf70421e61e0cd70cef7c5e1\n",
      "Successfully built keras-tuner terminaltables\n",
      "Installing collected packages: tabulate, terminaltables, keras-tuner\n",
      "Successfully installed keras-tuner-1.0.2 tabulate-0.8.7 terminaltables-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    input1 = Input(shape=(28 * 28,))\n",
    "    hidden1 = Dense(512)(input1)\n",
    "    hidden2 = BatchNormalization()(hidden1)\n",
    "    hidden3 = Activation('relu')(hidden2)\n",
    "    hidden4 = Dropout(0.5)(hidden3)\n",
    "\n",
    "    hidden5 = Dense(hp.Int('units',\n",
    "                            min_value=32,\n",
    "                            max_value=256,\n",
    "                            step=32))(hidden4)\n",
    "    hidden6 = BatchNormalization()(hidden5)\n",
    "    hidden7 = Activation('relu')(hidden6)\n",
    "\n",
    "    output = Dense(10, activation='softmax')(hidden7)\n",
    "\n",
    "    model = Model(inputs=input1, outputs=output)\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            hp.Choice('learning_rate',\n",
    "                      values=[1e-2, 1e-3, 1e-4])), \n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy', 'mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='./test',\n",
    "    project_name='helloworld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 04m 17s]\n",
      "val_accuracy: 0.9759333332379659\n",
      "\n",
      "Best val_accuracy So Far: 0.9786999821662903\n",
      "Total elapsed time: 00h 21m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train,\n",
    "             epochs=5,\n",
    "             validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./test/helloworld\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.001\n",
      "Score: 0.9786999821662903\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "learning_rate: 0.01\n",
      "Score: 0.9780666629473368\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 64\n",
      "learning_rate: 0.01\n",
      "Score: 0.9761333266894022\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 256\n",
      "learning_rate: 0.01\n",
      "Score: 0.9759333332379659\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "units: 160\n",
      "learning_rate: 0.0001\n",
      "Score: 0.9699333310127258\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
